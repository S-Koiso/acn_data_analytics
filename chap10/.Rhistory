data.dist <- dist(data.scale, method = "euclidean")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: install dataset and scaling
data.orig <- read.csv("http://enterprisezine.jp/static/images/article/6873/flat35_research_2013.csv", header=TRUE, row.names="都道府県", fileEncoding="UTF-8")
head(data.orig)
# scaling to make the average as 0 and std as 1
data.scale <- scale(data.orig)
data.dist <- dist(data.scale, method = "euclidean")
data.dist
data.dist <- dist(data.scale, method = "euclidean")
?hclust
plot(ward.hclust, hang=-1)
# clustering
ward.hclust <- hclust(data.dist, method = "ward.D2")
plot(ward.hclust, hang=-1)
plot(ward.hclust)
plot(ward.hclust, hang = -1)
# flip the dendrogram 90 degree
plot(as.dendrogram(ward.hclust), horiz = T, main = "Hierarchical Clustering Dendrogram (Ward)")
heatmap(data.scale, Rowv = as.dendrogram(ward.hclust), Colv = NA, scale = "none", main = "Heat Map for Hierarcical Clustering (Ward)")
?heatmap
#category by # of cluster
ward.cutree <- cutree(ward.hclust, k=2:4)
ward.cutree
plot(ward.hclust, hang = -1)
rect.hclust(ward.hclust, k=3, border = "red")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: install dataset and scaling
data.orig <- read.csv("http://enterprisezine.jp/static/images/article/6873/flat35_research_2013.csv", header=TRUE, row.names="都道府県", fileEncoding="UTF-8")
head(data.orig)
# scaling to make the average as 0 and std as 1
data.scale <- scale(data.orig)
# Chunk 3: ward
data.dist <- dist(data.scale, method = "euclidean")
data.dist
# clustering
ward.hclust <- hclust(data.dist, method = "ward.D2")
# If you dont know which argument to choose,
?hclust
# Chunk 4: ward visual
# visualize the dendrogram
plot(ward.hclust, hang = -1) # hang: to align the labels
# flip the dendrogram 90 degree
plot(as.dendrogram(ward.hclust), horiz = T, main = "Hierarchical Clustering Dendrogram (Ward)")
# Chunk 5: heatmap
# heatmap
heatmap(data.scale, Rowv = as.dendrogram(ward.hclust), Colv = NA, scale = "none", main = "Heat Map for Hierarcical Clustering (Ward)")
#category by # of cluster
ward.cutree <- cutree(ward.hclust, k=2:4)
ward.cutree
# Chunk 6: plot with boundaries
plot(ward.hclust, hang = -1)
rect.hclust(ward.hclust, k=3, border = "red")
plot(ward.hclust, hang = -1)
rect.hclust(ward.hclust, k=3, border = "red")
plot(ward.hclust, hang = -1)
rect.hclust(ward.hclust, k=3, border = "red")
## 10.3 Non-Hierarchical Clustering
K-Means clustering is one main example of non-hierarchical clustering.
### decide on the number of clusters
We need to choose the number of clusters **before** conducting the K-Means method.
```{r install package, include=FALSE}
install.packages("NbClust", repos = "http://cran.us.r-project.org")
library(NbClust)
km.best.nc <- NbClust(data.scale, distance = "Euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "alllong")
km.best.nc <- NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "alllong")
km.best.nc <- NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "alllong")
# Hubert
km.best.nc <- NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "hubert")
# Hubert
NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "hubert")
# Dindex
NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "dindex")
km.best.nc$Best.nc
km.best.nc
km.best.nc <- NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "alllong")
# Hubert
NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "hubert")
# Dindex
NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "dindex")
```{r indexes}
km.best.nc
km.best.nc$Best.nc
km.best.nc <- NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "alllong")
# Hubert
NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "hubert")
km.best.nc <- NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "alllong")
# Hubert
NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "hubert")
# Dindex
NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "dindex")
```{r discard PeudoT2 and Frey}
km.best.nc$Best.nc
km.best.nc <- NbClust(data.scale, distance = "euclidean", min.nc=2, max.nc = 10, method = "kmeans", index = "alllong")
km <- kmeans(data.scale, centers = 2, nstart = 10)
km
library(cluster)
clusplot(data.scale, km$cluster,color =T, lines=3,labels=2)
